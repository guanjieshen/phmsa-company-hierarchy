{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHMSA Company Hierarchy Analysis - Agent-Based Approach\n",
    "\n",
    "**Version 2.2** - LangChain ReAct Agents with DuckDuckGo Search\n",
    "\n",
    "This notebook identifies parent-subsidiary relationships in PHMSA pipeline operator data using:\n",
    "- **Agent-Based Search**: AI agent automatically decides when and how to search\n",
    "- **Dynamic Reasoning**: Iterative query formulation based on results\n",
    "- **Recency Validation**: Prioritizes 2024-2026 information\n",
    "- **Graph Resolution**: Computes ultimate parents and hierarchy chains\n",
    "\n",
    "**Runtime**: ~2-4 hours for 1000 companies on Databricks Serverless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "# Run this first, then restart Python\n",
    "\n",
    "%pip install -U langchain-community langchain-core langchain duckduckgo-search ddgs pandas networkx\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Initialize LLM and Search Tool\n",
    "\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "print(\"Initializing LLM and search tool...\")\n",
    "\n",
    "# Initialize Claude 3.5 Sonnet via Databricks\n",
    "llm = ChatDatabricks(\n",
    "    endpoint=\"databricks-claude-sonnet-4-5\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# Initialize DuckDuckGo search\n",
    "search_tool = DuckDuckGoSearchResults(num_results=5)\n",
    "\n",
    "print(\"âœ“ LLM and search tool initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Import Hierarchy Analysis Package\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Workspace/Repos/YOUR_USERNAME/phmsa-company-hierarchy/')  # UPDATE THIS PATH\n",
    "\n",
    "from phmsa_hierarchy import AgentLLMValidator, HierarchyGraphBuilder\n",
    "\n",
    "# Initialize components\n",
    "llm_validator = AgentLLMValidator(llm, search_tool)\n",
    "graph_builder = HierarchyGraphBuilder()\n",
    "\n",
    "print(\"âœ“ Agent validator and graph builder initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Load PHMSA Data\n",
    "\n",
    "# Load your PHMSA data from Unity Catalog\n",
    "companies_df = spark.read.table(\"gshen_catalog.enbridge_sr_workshop.annual_hazardous_liquid_2024_updated\")\n",
    "\n",
    "# Select required columns\n",
    "companies_df = companies_df.select(\n",
    "    \"OPERATOR_ID\",\n",
    "    \"PARTA2NAMEOFCOMP\",\n",
    "    \"PARTA4STREET\",\n",
    "    \"PARTA4CITY\",\n",
    "    \"PARTA4STATE\"\n",
    ").distinct()\n",
    "\n",
    "print(f\"Loaded {companies_df.count()} unique companies\")\n",
    "display(companies_df.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Prepare Company List for Validation\n",
    "\n",
    "# Collect all company names (parent must exist in this list)\n",
    "all_companies = [row[\"PARTA2NAMEOFCOMP\"] for row in companies_df.select(\"PARTA2NAMEOFCOMP\").distinct().collect()]\n",
    "\n",
    "# Broadcast to all workers\n",
    "available_companies_broadcast = spark.sparkContext.broadcast(all_companies)\n",
    "\n",
    "print(f\"âœ“ Prepared list of {len(all_companies)} companies for validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Define Pandas UDF for Agent-Based Validation\n",
    "\n",
    "from pyspark.sql.functions import pandas_udf, struct, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, BooleanType\n",
    "import pandas as pd\n",
    "\n",
    "# Define output schema\n",
    "output_schema = StructType([\n",
    "    StructField(\"OPERATOR_ID\", IntegerType(), True),\n",
    "    StructField(\"ORIGINAL_NAME\", StringType(), True),\n",
    "    StructField(\"IMMEDIATE_PARENT\", StringType(), True),\n",
    "    StructField(\"CONFIDENCE\", IntegerType(), True),\n",
    "    StructField(\"REASONING\", StringType(), True),\n",
    "    StructField(\"ACQUISITION_DATE\", StringType(), True),\n",
    "    StructField(\"RECENT_CHANGE\", BooleanType(), True),\n",
    "    StructField(\"PARTA4STREET\", StringType(), True),\n",
    "    StructField(\"PARTA4CITY\", StringType(), True),\n",
    "    StructField(\"PARTA4STATE\", StringType(), True),\n",
    "])\n",
    "\n",
    "@pandas_udf(output_schema)\n",
    "def find_parent_agent(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Agent-based parent company finder using LangChain ReAct agents.\n",
    "    Processes a batch of companies in parallel.\n",
    "    \"\"\"\n",
    "    from langchain_community.chat_models import ChatDatabricks\n",
    "    from langchain_community.tools import DuckDuckGoSearchResults\n",
    "    import sys\n",
    "    sys.path.append('/Workspace/Repos/YOUR_USERNAME/phmsa-company-hierarchy/')  # UPDATE THIS\n",
    "    from phmsa_hierarchy import AgentLLMValidator\n",
    "    \n",
    "    # Initialize for this worker\n",
    "    llm_local = ChatDatabricks(\n",
    "        endpoint=\"databricks-claude-sonnet-4-5\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    search_tool_local = DuckDuckGoSearchResults(num_results=5)\n",
    "    validator = AgentLLMValidator(llm_local, search_tool_local)\n",
    "    \n",
    "    # Set available companies\n",
    "    available_companies = available_companies_broadcast.value\n",
    "    validator.set_available_companies(available_companies)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, row in data.iterrows():\n",
    "        company_name = row[\"PARTA2NAMEOFCOMP\"]\n",
    "        operator_id = row[\"OPERATOR_ID\"]\n",
    "        address = f\"{row['PARTA4STREET']}, {row['PARTA4CITY']}, {row['PARTA4STATE']}\"\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"ðŸ¤– Processing [{idx+1}/{len(data)}]: {company_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # Use agent to find parent\n",
    "            result = validator.validate_direct(\n",
    "                company_name=company_name,\n",
    "                operator_id=operator_id,\n",
    "                address=address\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                \"OPERATOR_ID\": operator_id,\n",
    "                \"ORIGINAL_NAME\": company_name,\n",
    "                \"IMMEDIATE_PARENT\": result[\"parent\"],\n",
    "                \"CONFIDENCE\": result[\"confidence\"],\n",
    "                \"REASONING\": result[\"reasoning\"],\n",
    "                \"ACQUISITION_DATE\": result.get(\"acquisition_date\"),\n",
    "                \"RECENT_CHANGE\": result.get(\"recent_change\", False),\n",
    "                \"PARTA4STREET\": row[\"PARTA4STREET\"],\n",
    "                \"PARTA4CITY\": row[\"PARTA4CITY\"],\n",
    "                \"PARTA4STATE\": row[\"PARTA4STATE\"],\n",
    "            })\n",
    "            \n",
    "            print(f\"âœ… Result: {result['parent']} (confidence: {result['confidence']})\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing {company_name}: {str(e)}\")\n",
    "            results.append({\n",
    "                \"OPERATOR_ID\": operator_id,\n",
    "                \"ORIGINAL_NAME\": company_name,\n",
    "                \"IMMEDIATE_PARENT\": \"ERROR\",\n",
    "                \"CONFIDENCE\": 0,\n",
    "                \"REASONING\": f\"Error: {str(e)}\",\n",
    "                \"ACQUISITION_DATE\": None,\n",
    "                \"RECENT_CHANGE\": False,\n",
    "                \"PARTA4STREET\": row[\"PARTA4STREET\"],\n",
    "                \"PARTA4CITY\": row[\"PARTA4CITY\"],\n",
    "                \"PARTA4STATE\": row[\"PARTA4STATE\"],\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"âœ“ Agent-based UDF defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Run Agent-Based Analysis (This takes 2-4 hours for 1000 companies)\n",
    "\n",
    "print(\"Starting agent-based parent company analysis...\")\n",
    "print(f\"Processing {companies_df.count()} companies\")\n",
    "print(\"Agent will automatically search and reason for each company\")\n",
    "print(\"\\nThis will take approximately 2-4 hours. Progress will be shown below.\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Apply agent-based validation\n",
    "parent_mappings_df = companies_df.select(\n",
    "    find_parent_agent(\n",
    "        struct(\n",
    "            \"OPERATOR_ID\",\n",
    "            \"PARTA2NAMEOFCOMP\",\n",
    "            \"PARTA4STREET\",\n",
    "            \"PARTA4CITY\",\n",
    "            \"PARTA4STATE\"\n",
    "        )\n",
    "    ).alias(\"result\")\n",
    ").select(\"result.*\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"âœ“ Processed {parent_mappings_df.count()} companies\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Show sample results\n",
    "display(parent_mappings_df.limit(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Build Hierarchy Graph\n",
    "\n",
    "print(\"Building hierarchy graph...\")\n",
    "\n",
    "# Convert to pandas for graph building\n",
    "parent_mappings_pd = parent_mappings_df.toPandas()\n",
    "\n",
    "# Rename columns for graph builder\n",
    "parent_mappings_pd = parent_mappings_pd.rename(columns={\n",
    "    \"ORIGINAL_NAME\": \"child\",\n",
    "    \"IMMEDIATE_PARENT\": \"parent\"\n",
    "})\n",
    "\n",
    "# Build hierarchy graph\n",
    "hierarchy_df = graph_builder.build(parent_mappings_pd)\n",
    "\n",
    "print(f\"âœ“ Built hierarchy graph with {len(hierarchy_df)} companies\")\n",
    "\n",
    "# Show sample hierarchy results\n",
    "print(\"\\nSample hierarchy paths:\")\n",
    "print(hierarchy_df[['company', 'ultimate_parent', 'hierarchy_path', 'hierarchy_depth']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Get Statistics\n",
    "\n",
    "from pyspark.sql.functions import col, count, avg\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ANALYSIS STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Parent distribution\n",
    "print(\"\\n1. Parent Company Distribution:\")\n",
    "parent_dist = parent_mappings_df.groupBy(\"IMMEDIATE_PARENT\").count().orderBy(col(\"count\").desc())\n",
    "display(parent_dist.limit(20))\n",
    "\n",
    "# Confidence distribution\n",
    "print(\"\\n2. Confidence Score Distribution:\")\n",
    "confidence_stats = parent_mappings_df.select(\n",
    "    avg(\"CONFIDENCE\").alias(\"avg_confidence\"),\n",
    "    count(\"*\").alias(\"total_companies\")\n",
    ").collect()[0]\n",
    "print(f\"   Average Confidence: {confidence_stats['avg_confidence']:.2f}\")\n",
    "print(f\"   Total Companies: {confidence_stats['total_companies']}\")\n",
    "\n",
    "# Recent changes\n",
    "print(\"\\n3. Recent Ownership Changes (2024-2026):\")\n",
    "recent_changes = parent_mappings_df.filter(col(\"RECENT_CHANGE\") == True)\n",
    "print(f\"   Companies with recent changes: {recent_changes.count()}\")\n",
    "display(recent_changes.select(\"ORIGINAL_NAME\", \"IMMEDIATE_PARENT\", \"ACQUISITION_DATE\", \"REASONING\").limit(10))\n",
    "\n",
    "# Ultimate parent distribution\n",
    "print(\"\\n4. Ultimate Parent Distribution:\")\n",
    "hierarchy_spark_df = spark.createDataFrame(hierarchy_df)\n",
    "ultimate_parent_dist = hierarchy_spark_df.groupBy(\"ultimate_parent\").count().orderBy(col(\"count\").desc())\n",
    "display(ultimate_parent_dist.limit(20))\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Review Agent Reasoning (Quality Check)\n",
    "\n",
    "print(\"Sample agent reasoning for quality assurance:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show examples of high confidence results\n",
    "high_conf = parent_mappings_df.filter(col(\"CONFIDENCE\") >= 8).limit(5)\n",
    "print(\"\\nHigh Confidence Results (8-10):\")\n",
    "for row in high_conf.collect():\n",
    "    print(f\"\\n{row['ORIGINAL_NAME']} â†’ {row['IMMEDIATE_PARENT']}\")\n",
    "    print(f\"Confidence: {row['CONFIDENCE']}\")\n",
    "    print(f\"Reasoning: {row['REASONING'][:200]}...\")\n",
    "\n",
    "# Show examples of low confidence results (may need review)\n",
    "low_conf = parent_mappings_df.filter(col(\"CONFIDENCE\") <= 5).limit(5)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Low Confidence Results (â‰¤5) - May Need Review:\")\n",
    "for row in low_conf.collect():\n",
    "    print(f\"\\n{row['ORIGINAL_NAME']} â†’ {row['IMMEDIATE_PARENT']}\")\n",
    "    print(f\"Confidence: {row['CONFIDENCE']}\")\n",
    "    print(f\"Reasoning: {row['REASONING'][:200]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Save Results to Unity Catalog\n",
    "\n",
    "# Convert hierarchy back to Spark DataFrame\n",
    "final_results = spark.createDataFrame(hierarchy_df)\n",
    "\n",
    "# Join with original parent mappings to get full details\n",
    "final_results = final_results.join(\n",
    "    parent_mappings_df,\n",
    "    final_results.company == parent_mappings_df.ORIGINAL_NAME,\n",
    "    \"left\"\n",
    ").select(\n",
    "    col(\"OPERATOR_ID\"),\n",
    "    col(\"company\").alias(\"COMPANY_NAME\"),\n",
    "    col(\"immediate_parent\"),\n",
    "    col(\"ultimate_parent\"),\n",
    "    col(\"hierarchy_path\"),\n",
    "    col(\"hierarchy_depth\"),\n",
    "    col(\"CONFIDENCE\"),\n",
    "    col(\"REASONING\"),\n",
    "    col(\"ACQUISITION_DATE\"),\n",
    "    col(\"RECENT_CHANGE\"),\n",
    "    col(\"PARTA4STREET\"),\n",
    "    col(\"PARTA4CITY\"),\n",
    "    col(\"PARTA4STATE\")\n",
    ")\n",
    "\n",
    "# Save to Unity Catalog\n",
    "output_table = \"gshen_catalog.enbridge_sr_workshop.phmsa_hierarchy_results\"\n",
    "\n",
    "final_results.write.mode(\"overwrite\").saveAsTable(output_table)\n",
    "\n",
    "print(f\"âœ“ Results saved to {output_table}\")\n",
    "print(f\"âœ“ Total records: {final_results.count()}\")\n",
    "print(\"\\nAnalysis complete! ðŸŽ‰\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
