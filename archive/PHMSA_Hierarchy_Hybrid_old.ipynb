{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PHMSA Company Hierarchy Analysis - Hybrid Approach\n",
        "\n",
        "This notebook implements a hybrid approach combining:\n",
        "1. **Fuzzy Matching**: Find candidate parents within PHMSA dataset\n",
        "2. **LLM Validation**: Use LLM + web search to validate candidates\n",
        "3. **Graph Resolution**: Compute ultimate parents from immediate relationships\n",
        "\n",
        "## Benefits\n",
        "- **Higher Accuracy**: LLM sees real PHMSA candidates → better decisions\n",
        "- **Better Performance**: Fewer dead-end searches\n",
        "- **Extensible**: Easy to add new matching rules or swap LLM providers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Install dependencies\n",
        "%pip install -U langgraph langchain-community duckduckgo-search pandas\n",
        "dbutils.library.restartPython()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Initialize LLM and Search Tool\n",
        "import os\n",
        "import json\n",
        "from langchain_community.chat_models import ChatDatabricks\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "\n",
        "# Initialize Databricks-hosted Claude model\n",
        "llm = ChatDatabricks(\n",
        "    endpoint=\"databricks-claude-sonnet-4-5\",\n",
        "    extra_params={\"temperature\": 0, \"max_tokens\": 1000}\n",
        ")\n",
        "\n",
        "# Initialize DuckDuckGo search\n",
        "search_tool = DuckDuckGoSearchResults()\n",
        "\n",
        "print(\"✓ LLM and search tool initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Import Hybrid Modules\n",
        "import sys\n",
        "sys.path.append('/Workspace/Repos/phmsa-company-hierarchy/')  # Update with your repo path\n",
        "\n",
        "from phmsa_hierarchy import ParentCandidateFinder, LLMValidator, HierarchyGraphBuilder\n",
        "\n",
        "# Initialize the three stages\n",
        "candidate_finder = ParentCandidateFinder()\n",
        "llm_validator = LLMValidator(llm, search_tool)\n",
        "graph_builder = HierarchyGraphBuilder()\n",
        "\n",
        "print(\"✓ Hybrid modules imported and initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Load PHMSA Data\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# Load from Unity Catalog\n",
        "source_table = \"gshen_catalog.enbridge_sr_workshop.annual_hazardous_liquid_2024_updated\"\n",
        "\n",
        "# Get unique companies\n",
        "companies_df = spark.read.table(source_table) \\\n",
        "    .select(\"OPERATOR_ID\", \"PARTA2NAMEOFCOMP\", \"PARTA4STREET\", \"PARTA4CITY\", \"PARTA4STATE\") \\\n",
        "    .distinct()\n",
        "\n",
        "# For testing, limit to subset\n",
        "# companies_df = companies_df.limit(50)\n",
        "\n",
        "print(f\"✓ Loaded {companies_df.count()} unique companies\")\n",
        "\n",
        "# Collect all company names for fuzzy matching\n",
        "all_company_names = [row.PARTA2NAMEOFCOMP for row in companies_df.collect()]\n",
        "print(f\"✓ Collected {len(all_company_names)} company names for matching\")\n",
        "\n",
        "# Set companies in candidate finder\n",
        "candidate_finder.set_companies(all_company_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Define Output Schema\n",
        "schema = StructType([\n",
        "    StructField(\"OPERATOR_ID\", LongType(), True),\n",
        "    StructField(\"ORIGINAL_NAME\", StringType(), True),\n",
        "    StructField(\"IMMEDIATE_PARENT\", StringType(), True),\n",
        "    StructField(\"CANDIDATES_FOUND\", IntegerType(), True),\n",
        "    StructField(\"TOP_CANDIDATE\", StringType(), True),\n",
        "    StructField(\"CONFIDENCE\", IntegerType(), True),\n",
        "    StructField(\"REASONING\", StringType(), True),\n",
        "    StructField(\"ACQUISITION_DATE\", StringType(), True),\n",
        "    StructField(\"RECENT_CHANGE\", BooleanType(), True)\n",
        "])\n",
        "\n",
        "print(\"✓ Schema defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Define Hybrid Processing UDF\n",
        "@pandas_udf(schema)\n",
        "def find_parent_hybrid(ids, names, streets, cities, states):\n",
        "    \"\"\"\n",
        "    Hybrid approach: Fuzzy matching + LLM validation.\n",
        "    \n",
        "    Stage 1: Find candidate parents using fuzzy matching\n",
        "    Stage 2: Validate with LLM using web search\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    \n",
        "    for op_id, name, street, city, state in zip(ids, names, streets, cities, states):\n",
        "        try:\n",
        "            # Stage 1: Find candidates\n",
        "            candidates = candidate_finder.find_candidates(name)\n",
        "            \n",
        "            # Stage 2: Validate with LLM\n",
        "            address = f\"{street}, {city}, {state}\"\n",
        "            parent_info = llm_validator.validate(\n",
        "                company_name=name,\n",
        "                candidates=candidates,\n",
        "                operator_id=op_id,\n",
        "                address=address\n",
        "            )\n",
        "            \n",
        "            results.append({\n",
        "                \"OPERATOR_ID\": op_id,\n",
        "                \"ORIGINAL_NAME\": name,\n",
        "                \"IMMEDIATE_PARENT\": parent_info[\"parent\"],\n",
        "                \"CANDIDATES_FOUND\": len(candidates),\n",
        "                \"TOP_CANDIDATE\": candidates[0][\"name\"] if candidates else None,\n",
        "                \"CONFIDENCE\": parent_info[\"confidence\"],\n",
        "                \"REASONING\": parent_info[\"reasoning\"],\n",
        "                \"ACQUISITION_DATE\": parent_info.get(\"acquisition_date\"),\n",
        "                \"RECENT_CHANGE\": parent_info.get(\"recent_change\", False)\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Handle errors gracefully\n",
        "            results.append({\n",
        "                \"OPERATOR_ID\": op_id,\n",
        "                \"ORIGINAL_NAME\": name,\n",
        "                \"IMMEDIATE_PARENT\": \"ERROR\",\n",
        "                \"CANDIDATES_FOUND\": 0,\n",
        "                \"TOP_CANDIDATE\": None,\n",
        "                \"CONFIDENCE\": 0,\n",
        "                \"REASONING\": f\"Processing failed: {str(e)}\",\n",
        "                \"ACQUISITION_DATE\": None,\n",
        "                \"RECENT_CHANGE\": False\n",
        "            })\n",
        "    \n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "print(\"✓ Hybrid UDF defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Process Companies (Stages 1 & 2)\n",
        "print(\"Starting hybrid processing...\")\n",
        "\n",
        "# Apply hybrid UDF\n",
        "parent_mappings_df = companies_df.select(\n",
        "    find_parent_hybrid(\n",
        "        \"OPERATOR_ID\", \n",
        "        \"PARTA2NAMEOFCOMP\", \n",
        "        \"PARTA4STREET\", \n",
        "        \"PARTA4CITY\", \n",
        "        \"PARTA4STATE\"\n",
        "    ).alias(\"result\")\n",
        ").select(\"result.*\")\n",
        "\n",
        "# Cache for performance\n",
        "parent_mappings_df.cache()\n",
        "\n",
        "print(f\"✓ Processed {parent_mappings_df.count()} companies\")\n",
        "\n",
        "# Show sample results\n",
        "display(parent_mappings_df.limit(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Build Hierarchy Graph (Stage 3)\n",
        "print(\"Building hierarchy graph...\")\n",
        "\n",
        "# Convert to pandas for graph building\n",
        "parent_mappings_pd = parent_mappings_df.toPandas()\n",
        "\n",
        "# Rename columns for graph builder\n",
        "parent_mappings_pd = parent_mappings_pd.rename(columns={\n",
        "    \"ORIGINAL_NAME\": \"child\",\n",
        "    \"IMMEDIATE_PARENT\": \"parent\"\n",
        "})\n",
        "\n",
        "# Build hierarchy graph\n",
        "hierarchy_df = graph_builder.build(parent_mappings_pd)\n",
        "\n",
        "print(f\"✓ Built hierarchy graph with {len(hierarchy_df)} companies\")\n",
        "\n",
        "# Show sample hierarchy results\n",
        "print(\"\\nSample hierarchy paths:\")\n",
        "print(hierarchy_df[['company', 'ultimate_parent', 'hierarchy_path', 'hierarchy_depth']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Get Statistics\n",
        "print(\"=== Graph Statistics ===\")\n",
        "stats = graph_builder.get_statistics()\n",
        "for key, value in stats.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "print(\"\\n=== Confidence Distribution ===\")\n",
        "confidence_dist = parent_mappings_pd['CONFIDENCE'].value_counts().sort_index()\n",
        "print(confidence_dist)\n",
        "\n",
        "print(\"\\n=== Candidates Found Distribution ===\")\n",
        "candidates_dist = parent_mappings_pd['CANDIDATES_FOUND'].value_counts().sort_index()\n",
        "print(candidates_dist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Review Recent Ownership Changes\n",
        "print(\"=== Recent Ownership Changes (2024+) ===\\n\")\n",
        "\n",
        "recent_changes = parent_mappings_pd[parent_mappings_pd['RECENT_CHANGE'] == True]\n",
        "\n",
        "if len(recent_changes) > 0:\n",
        "    print(f\"Found {len(recent_changes)} companies with recent ownership changes:\\n\")\n",
        "    for _, row in recent_changes.iterrows():\n",
        "        print(f\"Company: {row['ORIGINAL_NAME']}\")\n",
        "        print(f\"  New Parent: {row['IMMEDIATE_PARENT']}\")\n",
        "        print(f\"  Acquisition Year: {row['ACQUISITION_DATE']}\")\n",
        "        print(f\"  Reasoning: {row['REASONING']}\")\n",
        "        print()\n",
        "    \n",
        "    print(\"⚠️  RECOMMENDATION: Manually verify these recent changes\")\n",
        "else:\n",
        "    print(\"No recent ownership changes detected (2024+)\")\n",
        "\n",
        "print(\"\\n✓ Recent changes review complete\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Save Results to Unity Catalog\n",
        "output_table = \"gshen_catalog.enbridge_sr_workshop.operator_hierarchy_hybrid\"\n",
        "\n",
        "# Convert hierarchy results back to Spark DataFrame\n",
        "hierarchy_spark_df = spark.createDataFrame(hierarchy_df)\n",
        "\n",
        "# Join with original parent mappings to get all fields\n",
        "final_df = hierarchy_spark_df.join(\n",
        "    parent_mappings_df,\n",
        "    hierarchy_spark_df.company == parent_mappings_df.ORIGINAL_NAME,\n",
        "    \"left\"\n",
        ").select(\n",
        "    \"OPERATOR_ID\",\n",
        "    parent_mappings_df.ORIGINAL_NAME,\n",
        "    \"immediate_parent\",\n",
        "    \"ultimate_parent\",\n",
        "    \"hierarchy_path\",\n",
        "    \"hierarchy_depth\",\n",
        "    \"has_cycle\",\n",
        "    \"CANDIDATES_FOUND\",\n",
        "    \"TOP_CANDIDATE\",\n",
        "    \"CONFIDENCE\",\n",
        "    \"REASONING\",\n",
        "    \"ACQUISITION_DATE\",\n",
        "    \"RECENT_CHANGE\"\n",
        ")\n",
        "\n",
        "# Save to Unity Catalog\n",
        "final_df.write.mode(\"overwrite\").saveAsTable(output_table)\n",
        "\n",
        "print(f\"✓ Results saved to: {output_table}\")\n",
        "print(f\"  Total records: {final_df.count()}\")\n",
        "\n",
        "# Display final results\n",
        "display(spark.table(output_table).limit(20))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
